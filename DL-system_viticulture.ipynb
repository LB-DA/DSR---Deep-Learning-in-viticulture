{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Deep Learning for viticulture (Main System)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "#os.chdir('..')\n",
    "print(os.getcwd())\n",
    "import tensorflow as tf\n",
    "from research.object_detection.utils import label_map_util\n",
    "import cv2\n",
    "import pandas as pd\n",
    "import xml.etree.ElementTree as ET\n",
    "import numpy as np\n",
    "from research.object_detection.utils import visualization_utils as vis_util\n",
    "from collections import deque"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Choose the object detection model to be used\n",
    "* set up the paths for the used model\n",
    "* oncluding: model name, path to chekpoint file, path to the used label map"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Prepare Paths\n",
    "# inference_graph and vine_label_label.pbtxt must be inside the model folder\n",
    "\n",
    "# select model\n",
    "MODEL_NAME = 'faster_rcnn_resnet101_coco'\n",
    "\n",
    "# Path to frozen detection graph. This is the actual model that is used for the object detection.\n",
    "PATH_TO_CKPT =os.path.join('vine_models', MODEL_NAME ,'frozen_inference_graph.pb')\n",
    "\n",
    "# List of the strings that is used to add correct label for each box.\n",
    "PATH_TO_LABELS =os.path.join('vine_models', MODEL_NAME , 'vine_label_map.pbtxt')\n",
    "\n",
    "NUM_CLASSES = 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Load the tensorflow model into memory\n",
    "detection_graph = tf.Graph()\n",
    "with detection_graph.as_default():\n",
    "  od_graph_def = tf.GraphDef()\n",
    "  with tf.gfile.GFile(PATH_TO_CKPT, 'rb') as fid:\n",
    "    serialized_graph = fid.read()\n",
    "    od_graph_def.ParseFromString(serialized_graph)\n",
    "    tf.import_graph_def(od_graph_def, name='')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Loading the label map\n",
    "label_map = label_map_util.load_labelmap(PATH_TO_LABELS)\n",
    "categories = label_map_util.convert_label_map_to_categories(label_map, max_num_classes=NUM_CLASSES, use_display_name=True)\n",
    "category_index = label_map_util.create_category_index(categories)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup Video for the Process\n",
    "* fill in the path to the video or just the name of it if it's in the same directory as the skript\n",
    "* with cap.set you can start at a specific MSEC Position in the video\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#Prepare the Video\n",
    "video_name = 'video_2'\n",
    "cap = cv2.VideoCapture(video_name+\".MP4\")\n",
    "cap.set(cv2.CAP_PROP_POS_MSEC,2000)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Detection of the movement direction of the video\n",
    "* initial short application of the object detection model on the video in order to identify the movement direction of the video\n",
    "* based on the displacement of detected objects over several frames, the movement direction is derived\n",
    "* when a certain threshold is met for the detection the direction gets identified"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "#Movement Detection\n",
    "\n",
    "with detection_graph.as_default():\n",
    "  with tf.Session(graph=detection_graph) as sess:\n",
    "    image_tensor = detection_graph.get_tensor_by_name('image_tensor:0')\n",
    "    detection_boxes = detection_graph.get_tensor_by_name('detection_boxes:0')\n",
    "    detection_scores = detection_graph.get_tensor_by_name('detection_scores:0')\n",
    "    detection_classes = detection_graph.get_tensor_by_name('detection_classes:0')\n",
    "    num_detections = detection_graph.get_tensor_by_name('num_detections:0')\n",
    "    \n",
    "    # variables to determine the movement direction\n",
    "    last_movement_label_xmax = 0\n",
    "    movement_counter = 0\n",
    "\n",
    "    \n",
    "    # Open the video file\n",
    "    while cap.isOpened():\n",
    "        _, image_np = cap.read()\n",
    "        image_np_expanded = np.expand_dims(image_np, axis=0)\n",
    "        # Predict the boxes with class and score\n",
    "        (boxes, scores, classes, num) = sess.run(\n",
    "          [detection_boxes, detection_scores, detection_classes, num_detections],\n",
    "          feed_dict={image_tensor: image_np_expanded})\n",
    "        \n",
    "        # Create a dict with information about predicted boxes\n",
    "        data = {'y_min': [boxes[0][i][0] for i in range(len(boxes[0]))],\n",
    "                'x_min': [boxes[0][i][1] for i in range(len(boxes[0]))],\n",
    "                'y_max': [boxes[0][i][2] for i in range(len(boxes[0]))],\n",
    "                'x_max': [boxes[0][i][3] for i in range(len(boxes[0]))],\n",
    "                'score': scores[0], \n",
    "                'class': classes[0]}\n",
    "        \n",
    "        # Store prediction dict in pandas DataFrame\n",
    "        df = pd.DataFrame(data=data, index=np.arange(0, len(boxes[0]), 1))\n",
    "        relevant_movement_label = df.loc[(df['class'] == 1) & (df['score'] > 0.7)]\n",
    "    \n",
    "        # Reset the index of the frame after slicing it\n",
    "        for frame in [relevant_movement_label]:\n",
    "            frame.reset_index(inplace=True)\n",
    "        \n",
    "        # Get minimal xmax as comparison value\n",
    "        current_movement_label_xmax = float(round(relevant_movement_label.loc[:, 'x_max'].min(), 10))\n",
    "        \n",
    "        # If the current minimal xmax is larger than the last one, the movement is going in right direction\n",
    "        # This allows to iron out movement mistakes due to unsteady camera movement or not moving frames\n",
    "        if current_movement_label_xmax > last_movement_label_xmax:\n",
    "            movement_counter = movement_counter + 1\n",
    "            print(movement_counter)\n",
    "        else:\n",
    "            movement_counter = movement_counter - 1\n",
    "            print(movement_counter)\n",
    "\n",
    "        last_movement_label_xmax = current_movement_label_xmax\n",
    "        \n",
    "        if movement_counter == 10 or movement_counter == -10:\n",
    "            break\n",
    "\n",
    "movement_detected = \"right\" if movement_counter == 10 else \"left\"\n",
    "print(\"identified movement direction: \" + str(movement_detected))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Start the video processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Start the video\n",
    "#release capture from the previous movement detection\n",
    "cap.release()\n",
    "cap = cv2.VideoCapture(video_name+\".MP4\")\n",
    "cap.set(cv2.CAP_PROP_POS_MSEC,2000)   # start the processing at a specific msec position in the video\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Configuration of Filter Values\n",
    "* change the filter parameters for the post filtering if needed\n",
    "* this might be needed for videos with a different camera angle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_threshold = 0.7                  # y_max > y_threshold -> used to ignore vines of the second row\n",
    "y2_threshold = 0.8                 # y_min < y2_threshold\n",
    "search_field_upper_border = 0.5    # upper limit of the search field criteria\n",
    "search_field_lower_border = 0.8    # lower limit of the search field criteria\n",
    "                                   # for this search field setting: only keep detection-boxes if its center lies between\n",
    "                                   # 50% and 80% of the image height. -> used to focus the tracking on the vine area\n",
    "                                   # if needed this can be adapted for a different camera angle"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Initiate Variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "w = 1920 #1280 # 1920                    # set up width and height of used video -> important for visualization of the object tracking\n",
    "h = 1080 #720  # 1080                    # not mandatory for the actual functionallity\n",
    "\n",
    "movement = movement_detected             # result from movement detection. \"right\" = vine moves from left to right     \n",
    "\n",
    "exit_zone_right = 0.92                   # set up exit_zones for entities\n",
    "exit_zone_left = 0.08\n",
    "\n",
    "avg_speed = 0                           \n",
    "\n",
    "buffer = 20                             # size of deque objects\n",
    "\n",
    "entity_list = []                        # saves the entity-deque-objects\n",
    "\n",
    "\n",
    "\n",
    "last_time_modified = []                 # saves the last frame  an entity of the entity_list has been modified\n",
    "current_speed = []                      # current speed of an entity\n",
    "is_active = []                          # condition of the entity -> is it active? (Boolen) \n",
    "expected_next_center = []               # calculated expected center for entities\n",
    "\n",
    "\n",
    "average_movement_speed = 0               # average speed of all active entities\n",
    "frame_counter = 0                        # current frame number\n",
    "\n",
    "active_entities = []                     # all currently active entities\n",
    "\n",
    "vine_counter = 0                         # counts how many vines were detected at current frame\n",
    "is_entity_counted = []                   # Boolean; enables counting tracked vines only once\n",
    "count_threshold = 10                     # set up how many times an object has to be tracked in order to be counted\n",
    "\n",
    "entity_distance = []                     # distances of entities to the next entity\n",
    "entity_MSEC = []                         # MSEC Positions of Entities if they get deactivated\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### OBJECT DETECTION / POST FILTERING / OBJECT TRACKER / OBJECT COUNTER"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#deploy the model on each frame\n",
    "with detection_graph.as_default():\n",
    "  with tf.Session(graph=detection_graph) as sess:\n",
    "    \n",
    "    #<---------------------------------------------- START OF: OBJECT DETECTION   ------------------------------------------>\n",
    "    \n",
    "    ############################################ START OF: PREPARE THE MODEL> #######################################\n",
    "    # Definite input and output Tensors for detection_graph\n",
    "    image_tensor = detection_graph.get_tensor_by_name('image_tensor:0')\n",
    "    # get detection-boxes\n",
    "    # Each box represents a part of the image where a particular object was detected.\n",
    "    # for this given use case detection-boxes can be vines, woodensticks, or metalsticks (trained classes of the model)\n",
    "    detection_boxes = detection_graph.get_tensor_by_name('detection_boxes:0')\n",
    "    detection_scores = detection_graph.get_tensor_by_name('detection_scores:0')\n",
    "    detection_classes = detection_graph.get_tensor_by_name('detection_classes:0')\n",
    "    num_detections = detection_graph.get_tensor_by_name('num_detections:0')\n",
    "    ############################################ END OF: PREPARE THE MODEL> ########################################\n",
    "    \n",
    "    \n",
    "    ############################################ START OF: RUN THE MODEL> ##########################################\n",
    "    \n",
    "    while(cap.isOpened()):\n",
    "      #returns numpy.ndarray with shape (1080, 1920, 3) for each videoframe\n",
    "      #from now on every further step is always applied to a single frame\n",
    "      (ret, image_np) = cap.read() \n",
    "      if not ret:\n",
    "            break\n",
    "      \n",
    "      # increment the frame_counter variable for each frame in order to save the current frame number     \n",
    "      frame_counter += 1\n",
    "      # also save frame counter as tuple -> used for speed normalization later on\n",
    "      frame_counter_tuple = (frame_counter,) \n",
    "        \n",
    "      # Expand dimensions since the model expects input to have shape (1,1080,1920,3) given full hd images\n",
    "      image_np_expanded = np.expand_dims(image_np, axis=0)\n",
    "      \n",
    "      # run the detection model\n",
    "      # it returns the x and y coordinates for the boxes, the score, the classes and num  \n",
    "      (boxes, scores, classes, num) = sess.run(\n",
    "          [detection_boxes, detection_scores, detection_classes, num_detections],\n",
    "          feed_dict={image_tensor: image_np_expanded}) \n",
    "      \n",
    "\n",
    "      # get all coordinates, score and class of each detection-boxes for the class = 0\n",
    "      # in this case class 0 = vine, class 1 = woodenstick, class 2 = metalstick\n",
    "      data = {'y_min': [boxes[0][i][0] for i in range(len(boxes[0]))],\n",
    "                'x_min': [boxes[0][i][1] for i in range(len(boxes[0]))],\n",
    "                'y_max': [boxes[0][i][2] for i in range(len(boxes[0]))],\n",
    "                'x_max': [boxes[0][i][3] for i in range(len(boxes[0]))],\n",
    "                'score': scores[0], \n",
    "                'class': classes[0]}\n",
    "  \n",
    "      # create a dataframe which contains all detection-boxes for the label/class vine of the current frame\n",
    "      df = pd.DataFrame(data=data, index=np.arange(0, len(boxes[0]), 1))\n",
    "        \n",
    "      ############################################ END OF: RUN THE MODEL> ################################################\n",
    "    \n",
    "      #<---------------------------------------------- END OF: OBJECT DETECTION   ------------------------------------------>\n",
    "        \n",
    "       \n",
    "    \n",
    "    \n",
    "        \n",
    "       \n",
    "      #<---------------------------------------------- START OF: POST FILTERING   ------------------------------------------>   \n",
    "          \n",
    "      ############################################ START OF: POST FILTER 1> ################################################\n",
    "    \n",
    "      # only use labels which have a score above 70%\n",
    "      # only use labels whose y-max coordinates are above y_threshold (see filter setup above)\n",
    "      # (optional:  only use labels whose y-min coordinates are below y2_threshold (see filter setup above))\n",
    "      # relevant_labels contains all labels that met these requirements \n",
    "      relevant_labels = df.loc[(df['score'] > 0.7) & (df['class'] == 1.0) & (df['y_max'] > y_threshold) & (df['y_min'] < y2_threshold) ]\n",
    "    \n",
    "      # contains all labels which met the first filter criteria\n",
    "      labels_df = relevant_labels.values                                          \n",
    "      ############################################## END OF: POST FILTER 1> ################################################\n",
    "        \n",
    "    \n",
    "      ############################################ START OF: POST FILTER 2> ################################################\n",
    "        \n",
    "      # create labels list which will contain all labels which met this first and second filter criteria\n",
    "      # this label list is created for each frame  \n",
    "      labels = []\n",
    "      # get values for each detection-box\n",
    "      for i in range(0,len(labels_df)):\n",
    "            score = (labels_df[i][1])\n",
    "            x_max = (labels_df[i][2])\n",
    "            x_min = (labels_df[i][3])\n",
    "            y_max = (labels_df[i][4])\n",
    "            y_min = (labels_df[i][5])\n",
    "     \n",
    "            # calculate the center y-coordinate of a detection box\n",
    "            center_y = (y_min+(y_max-y_min)/2)\n",
    "            \n",
    "            ## SEARCH FIELD CHEKCER ##\n",
    "            # only keep an detection-box if its center y-coordinate lies between a given range (upper/lower_seach_field)\n",
    "            # calculate the center of each detection box\n",
    "            center = (float(x_min + (x_max-x_min)/2),float(y_min+(y_max-y_min)/2)) #is tuple\n",
    "            if search_field_lower_border > center_y > search_field_upper_border :  \n",
    "                # if a label meets this criteria, it is added to the labels list as following:\n",
    "                # labels= [assigned, center(x,y), y_min, x_min, y_max, x_max]\n",
    "                # assigned = False means, that is has not beed assigned to an entity yet\n",
    "                # this assigned status will be used for the object racking method later on\n",
    "                data2 = [False, center, y_min, x_min, y_max, x_max,score]          \n",
    "                labels.append(data2)\n",
    "            else:\n",
    "                print(\"an detection-box did not met the filter criteria 2\")\n",
    "                \n",
    "    ############################################## END OF: POST FILTER 2> ################################################ \n",
    "    \n",
    "    ############################################ START OF: POST FILTER 3> ################################################\n",
    "\n",
    "\n",
    "      # eleminate overlapping labels\n",
    "      # did the model detect any labels on this frame?  \n",
    "      if len(labels) > 0:\n",
    "          # setup a condition as False\n",
    "          #       \n",
    "          condition = False\n",
    "          while condition == False:\n",
    "\n",
    "              # final_label_list will contain all non overlapping detection-boxes objects for this iteration\n",
    "              # it will be used as initial labels list for further iterations\n",
    "              final_label_list = []\n",
    "\n",
    "              #check for each label:\n",
    "              for label in labels:\n",
    "                  #get xmin and xmax of label in order to compare with x-values of other labels\n",
    "                  label_round_xmin_checker = label[3]\n",
    "                  label_round_xmax_checker = label[5]\n",
    "\n",
    "                  # labels_checker list will contain all overlapping labels for the specific label of this iteration\n",
    "                  labels_checker = []\n",
    "\n",
    "                  # new_label_list will contain the label with the highest score of labels_checker\n",
    "                  new_label_list = []\n",
    "\n",
    "                  # check whether label is overlapping with others or not\n",
    "                  for label_check in labels:\n",
    "                      # skip label_check with chosen label itself\n",
    "                      if label_round_xmin_checker == label_check[3] and label_round_xmax_checker == label_check[5]:\n",
    "                          break\n",
    "                      else:  \n",
    "                          # if a xmin or xmax value of the given lies within the xmin-xmax range of another label, these labels are overlapping each other\n",
    "                          # add overlapping label for further comparison to labels_ckecker list\n",
    "                          # checking range is also slightly expanded by 5% of the image width in each direction\n",
    "                          # this can also match very close detection-boxes which are nearly overlapping  \n",
    "                          if label_check[3] - 0.05 < label_round_xmin_checker < label_check[5] + 0.05 or label_check[3] - 0.05 < label_round_xmax_checker < label_check[5] + 0.05:    \n",
    "                              labels_checker.append(label_check)\n",
    "                          # label is not overlapping with any of the labels\n",
    "                          else:\n",
    "                              labels_checker = labels_checker\n",
    "\n",
    "                  # if the labels_ckecker list contains any candidates:\n",
    "                  # -> overlappings were detected\n",
    "                  # -> overlappings have to be resolver  \n",
    "                  if len(labels_checker) > 0:\n",
    "\n",
    "                        # add the actual label with which the overlap was detected to the checker list\n",
    "                        labels_checker.append(label)\n",
    "\n",
    "                        # compare score values for each label in labels_checker list\n",
    "                        for label_comparison in labels_checker:\n",
    "\n",
    "                            # if given label has the highest score of all labels in labels_checker list\n",
    "                            # add label to new_label_list (winner of score value comparison)\n",
    "                            if label_comparison[6] == max([sublist[6] for sublist in labels_checker]):\n",
    "                                new_label_list = label_comparison\n",
    "                            else:\n",
    "                                print(str(label_comparison[6])+\"was not the maximun score -> the label got deleted\")\n",
    "                                \n",
    "                        \n",
    "                  # if the labels_ckecker ist empty:\n",
    "                  # -> no overlappings were detected\n",
    "                  # -> label can be added right away to final_label_list\n",
    "                  else:        \n",
    "                      final_label_list.append(label)\n",
    "\n",
    "                  # add new_label list to final_label_list\n",
    "                  # only if final_label_list is not already containing the label from a previous iteration\n",
    "                  if len(new_label_list) > 0 and new_label_list not in final_label_list:\n",
    "                      final_label_list.append(new_label_list)\n",
    "\n",
    "\n",
    "              # final_label_list is the initial input labels list for next while iteration\n",
    "              # if: length of initial labels list equals length of output final_label_list \n",
    "              # -> no changes were made, meaning initial list is not containing any more overlapping labels\n",
    "              # -> change condition to True and exit while loop\n",
    "              # -> update the labels list with the filtered labels from the third filter criteria\n",
    "              #    the labels list now contains all detection-boxes which met filter criteria 1,2 and 3\n",
    "              if len(labels) == len(final_label_list):\n",
    "                  condition = True\n",
    "                  labels = final_label_list\n",
    "              # else: length is not euqal\n",
    "              # -> changes were made during this iteration\n",
    "              # -> condition stays False and the next iteraion begins  \n",
    "              else:\n",
    "                  condition = False\n",
    "                  labels = final_label_list \n",
    "      ############################################## END OF: POST FILTER 2> ################################################\n",
    "    \n",
    "      #<---------------------------------------------- END OF: POST FILTERING   ------------------------------------------>\n",
    "        \n",
    "        \n",
    "        \n",
    "        \n",
    "        \n",
    "        \n",
    "      \n",
    "      #<---------------------------------------------- START OF: OBJECT TRACKING   --------------------------------------->\n",
    "    \n",
    "      ########################################## START OF: ENTITY ASSIGNMENT    ###########################################\n",
    "        \n",
    "      # here the valid detection-boxes as the output of the post filtering are used for the Object Tracker  \n",
    "      # the assignment of valid detection-boxes to entities is based on 4 different cases:\n",
    "      # In order to track objects, entities are created and detection-boxes are matched with these entities over frames\n",
    "    \n",
    "      # !!!!!!!! keep in mind: the term \"label\" is used here for a valid detection-box of the labels list !!!!!!!!  \n",
    "        \n",
    "      if len(labels) > 0:                                        # did the model detect any labels on this frame?\n",
    "            \n",
    "          if is_active.count(True) > 0:                          # is there at least one active entity\n",
    "                                                                 # if there is no active entity -> case 1 is used\n",
    "                                                                 # -> in this case a new entity is created for the detection box\n",
    "                                                                 # (see case 1 at the bottom)\n",
    "                                                                 # case 1 is always the case for the first frame   \n",
    "                        \n",
    "          ## Entity Assignment Case 2: ##\n",
    "          # detection-box/label can be assigned to an active visible entity\n",
    "          # # check if label can be assigned to an hidden entity\n",
    "              \n",
    "              # get the nearest entity for current label\n",
    "              nearest_entity = []                                  # set up a nearest_entity list \n",
    "              for label in range(len(labels)):                     # iterate over labels  \n",
    "                    distance = []                                  # clear distance after each label\n",
    "                    visible_id = []\n",
    "                    for visible in visible_entities:               # iterate over visible entites     \n",
    "                        if last_time_modified[visible] != frame_counter: # avoid assiging multiple labels to one entity\n",
    "                                                                         # -> only proceed if the entity wasn't updated in this frame yet\n",
    "                            dis = abs(labels[label][1][0]-entity_list[visible][0][0])\n",
    "                            distance.append(dis)\n",
    "                            visible_id.append(visible)             # calculate the distance for a given label to each currently active visible entity \n",
    "                                                                   # append these distances to the distance list\n",
    "                    # if there are distances:            \n",
    "                    # get the index of the min value of distance and apply it as index to visible_id to get the ID of the nearest entity\n",
    "                    # the entity with the smallest entity to a given label is a nearest_entity\n",
    "                    if len(distance) > 0:\n",
    "                        nearest_entity.append(visible_id[distance.index(min(distance))])\n",
    "                        #nearest_entity = [ID , ID , ID , ID]\n",
    "                        \n",
    "                        \n",
    "                        # check if the detection-box/label was already assigned to another entity\n",
    "                        # and build a tolerance area (+/- 8% of image width/height around the center of nearest entities)\n",
    "                        if labels[label][0] == False and entity_list[nearest_entity[label]][0][0] -0.08 < labels[label][1][0] < entity_list[nearest_entity[label]][0][0] + 0.08 and entity_list[nearest_entity[label]][0][1] -0.08 < labels[label][1][1] < entity_list[nearest_entity[label]][0][1] + 0.08: \n",
    "                        \n",
    "                            # if the center of the label lies within a tolerance area of a visible entity:\n",
    "                            # -> update existing entity\n",
    "                            # -> update last position of entity with the center of the matching detection-box\n",
    "                            entity_list[nearest_entity[label]].appendleft(labels[label][1]+frame_counter_tuple)  \n",
    "                            # -> mark that this detection-box has been assigned to an entity \n",
    "                            labels[label][0] = True\n",
    "                            # -> update last modified frame number to the current frame number\n",
    "                            last_time_modified[nearest_entity[label]] = frame_counter \n",
    "                       \n",
    "          ## Entity Assignment Case 3: ##\n",
    "          # detection-box/label can be assigned to an active hidden entity\n",
    "          # check if label can be assigned to an hidden entity  \n",
    "        \n",
    "                    if labels[label][0] == False:                   # check if the detection-box/label was already assigned\n",
    "                        for hidden in hidden_entities:              # iterate over hidden entites\n",
    "                            if last_time_modified[hidden] != frame_counter: # avoid assiging multiple labels to one entity\n",
    "                                \n",
    "                                if labels[label][0] == False:\n",
    "\n",
    "\n",
    "                                    if movement == \"right\":                                  \n",
    "                                        # build tolerance area (+/- 10% of image width/height around the center of nearest entities)\n",
    "                                        # a larger tolerance area is used for hidden entities\n",
    "                                        # this is because for hidden entities calculated expected_next center is used (see below at UPDATE)\n",
    "                                        if expected_next_center[hidden]-0.1 < labels[label][1][0] < expected_next_center[hidden]+0.1 and entity_list[hidden][0][1]-0.1 < labels[label][1][1] < entity_list[hidden][0][1]+0.1:          # check for X and Y-position condition                \n",
    "                                            \n",
    "                                            # if the center of the label lies within a tolerance area of a hidden entity:\n",
    "                                            # -> update existing entity\n",
    "                                            # -> update expected position of hidden entity with the center of the matching detection-box/label\n",
    "                                            entity_list[hidden].appendleft(labels[label][1]+frame_counter_tuple)  \n",
    "                                            \n",
    "                                            # -> mark that this detection-box has been assigned to an entity\n",
    "                                            labels[label][0] = True\n",
    "                                            # -> update last modified frame number to the current frame number\n",
    "                                            last_time_modified[hidden] = frame_counter \n",
    "                                            \n",
    "                                    # the left case is for this implementation the same as the right case\n",
    "                                    # if needed it can be differentiated between the movement direction\n",
    "                                    # e.g. a larger tolerance area in the direction of movement can be used\n",
    "                                    elif movement == \"left\":\n",
    "                                        if expected_next_center[hidden]-0.1 < labels[label][1][0] < expected_next_center[hidden]+0.1 and entity_list[hidden][0][1]-0.1 < labels[label][1][1] < entity_list[hidden][0][1]+0.01:  \n",
    "                                  \n",
    "                                            entity_list[hidden].appendleft(labels[label][1]+frame_counter_tuple)  \n",
    "                                             \n",
    "                                            labels[label][0] = True\n",
    "                                            last_time_modified[hidden] = frame_counter \n",
    "\n",
    "          ## Entity Assignment Case 4: ##\n",
    "          # detection-box/label can not be assigned to an active visible entity or an active hidden entity\n",
    "          # check if a new entitiy must be created\n",
    "          # differentiates between left and right movement direction\n",
    "            \n",
    "                        if labels[label][0] == False:\n",
    "                            ## movement = left ##\n",
    "                            # the left case is basically the same but the check condition: exit_zone_left\n",
    "                            if movement == \"left\":\n",
    "                                \n",
    "                                if labels[label][1][0] < exit_zone_left:    # xmin of detection-box < exit zone  !!!! specific for right direction !!!!  \n",
    "                                                                            # dont open new entities in exit zone\n",
    "                                        \n",
    "                                    # additionally check if there are any visible or hidden entities near the label/d-box\n",
    "                                    # there might be an entity near it which has been updated\n",
    "                                    # in order to avoid the creation of a new entity near an existing one this check is done\n",
    "                                    distance2 = []                                  # get distance 2\n",
    "                                    visible_id2 = []                                # distance 2 = distances visible entities\n",
    "                                    dis0 = 10\n",
    "                                    distance2.append(dis0)                                     \n",
    "                                    for visible in visible_entities:                # iterate over all visible entites                                                                  \n",
    "                                        dis2 = abs(labels[label][1][0]-entity_list[visible][0][0])\n",
    "                                        distance2.append(dis2)\n",
    "                                        visible_id2.append(visible)                 \n",
    "                                    \n",
    "                                    distance3 = []                                  # get distance 3\n",
    "                                    visible_id3 = []                                # distance 3 = distances hidden entities \n",
    "                                    distance3.append(dis0)                          \n",
    "                                    for hidden in hidden_entities:                  # iterate over all hidden entities                      \n",
    "                                        dis3 = abs(labels[label][1][0]-entity_list[hidden][0][0])\n",
    "                                        distance3.append(dis3)\n",
    "                                        visible_id3.append(hidden)\n",
    "                                \n",
    "                                \n",
    "                                    if len(distance2) > 1 or len(distance3) > 1:    # check if a visible or hidden entitie is nearby\n",
    "                                            if -0.1 < min(distance2) < 0.1 or -0.1 < min(distance3) < 0.1: # tolerance area (+/- 10% width of image) \n",
    "                                                print(\"nearby entity -> it is not allowed \")\n",
    "\n",
    "                                            # -> enough distance to nearby existing entities\n",
    "                                            # -> create new entity\n",
    "                                            else:\n",
    "                                                                                               # create a new entity\n",
    "                                                entity = deque(maxlen = buffer)                # create new deque object for new entity\n",
    "                                                entity.appendleft(labels[label][1]+frame_counter_tuple)# append the center of current label\n",
    "                                                entity_list.append(entity)                     # append entity to entity_list                                    \n",
    "\n",
    "                                                labels[label][0] = True                        # D-Box has been assigned. assigned = True\n",
    "                                                last_time_modified.append(0)                   # append frame counter to the last_time_modified list\n",
    "                                                last_time_modified[entity_list.index(entity_list[-1])] = frame_counter \n",
    "\n",
    "                                                is_active.append(False)                        # set up entity as an active entity, since it's new\n",
    "                                                is_active[entity_list.index(entity_list[-1])] = True\n",
    "\n",
    "                                                is_entity_counted.append(False)                # entity has not been counted yet, since it's new\n",
    "\n",
    "                                                expected_next_center.append(labels[label][1][0]) # append entry for expected next center\n",
    "                                                current_speed.append(0)                        # append entry for current speed of the new entity\n",
    "\n",
    "                                    # if no distances are abailable:\n",
    "                                    # -> create new entity\n",
    "                                    # -> for entity creation see above: \n",
    "                                    else:\n",
    "                                        entity = deque(maxlen = buffer)                \n",
    "                                        entity.appendleft(labels[label][1]+frame_counter_tuple)\n",
    "                                        entity_list.append(entity)                     \n",
    "\n",
    "                                        labels[label][0] = True\n",
    "                                        last_time_modified.append(0)\n",
    "                                        last_time_modified[entity_list.index(entity_list[-1])] = frame_counter  \n",
    "\n",
    "                                        is_active.append(False)                         \n",
    "                                        is_active[entity_list.index(entity_list[-1])] = True\n",
    "\n",
    "                                        is_entity_counted.append(False)\n",
    "\n",
    "                                        expected_next_center.append(labels[label][1][0]) \n",
    "                                        current_speed.append(0)    \n",
    "                            \n",
    "                            # movement = right #\n",
    "                            else: \n",
    "                               \n",
    "                                if labels[label][1][0] < exit_zone_right:      # xmin of detection-box < exit zone    \n",
    "                                                                               # dont open new entities in exit zone\n",
    "                                        \n",
    "                                    # additionally check if there are any visible or hidden entities near the label/d-box\n",
    "                                    # there might be an entity near it which has been updated\n",
    "                                    # in order to avoid the creation of a new entity near an existing one this check is done\n",
    "                                    distance2 = []                                  # get distance 2\n",
    "                                    visible_id2 = []                                # distance 2 = distances visible entities\n",
    "                                    dis0 = 10\n",
    "                                    distance2.append(dis0)                                     \n",
    "                                    for visible in visible_entities:                # iterate over all visible entites                                                                  \n",
    "                                        dis2 = abs(labels[label][1][0]-entity_list[visible][0][0])\n",
    "                                        distance2.append(dis2)\n",
    "                                        visible_id2.append(visible)                 \n",
    "                                    \n",
    "                                    distance3 = []                                  # get distance 3\n",
    "                                    visible_id3 = []                                # distance 3 = distances hidden entities \n",
    "                                    distance3.append(dis0)                          \n",
    "                                    for hidden in hidden_entities:                  # iterate over all hidden entities                      \n",
    "                                        dis3 = abs(labels[label][1][0]-entity_list[hidden][0][0])\n",
    "                                        distance3.append(dis3)\n",
    "                                        visible_id3.append(hidden)\n",
    "                                        \n",
    "                                        \n",
    "                                    if len(distance2) > 1 or len(distance3) > 1:    # check if a visible or hidden entitie is nearby\n",
    "                                        if -0.1 < min(distance2) < 0.1 or -0.1 < min(distance3) < 0.1: # tolerance area (+/- 10% width of image) \n",
    "                                            print(\"nearby entity -> it is not allowed \")\n",
    "                                        \n",
    "                                        # -> enough distance to nearby existing entities\n",
    "                                        # -> create new entity\n",
    "                                        else:\n",
    "                                                                                           # create a new entity\n",
    "                                            entity = deque(maxlen = buffer)                # create new deque object for new entity\n",
    "                                            entity.appendleft(labels[label][1]+frame_counter_tuple)# append the center of current label\n",
    "                                            entity_list.append(entity)                     # append entity to entity_list                                    \n",
    "\n",
    "                                            labels[label][0] = True                        # D-Box has been assigned. assigned = True\n",
    "                                            last_time_modified.append(0)                   # append frame counter to the last_time_modified list\n",
    "                                            last_time_modified[entity_list.index(entity_list[-1])] = frame_counter \n",
    "\n",
    "                                            is_active.append(False)                        # set up entity as an active entity, since it's new\n",
    "                                            is_active[entity_list.index(entity_list[-1])] = True\n",
    "\n",
    "                                            is_entity_counted.append(False)                # entity has not been counted yet, since it's new\n",
    "\n",
    "                                            expected_next_center.append(labels[label][1][0]) # append entry for expected next center\n",
    "                                            current_speed.append(0)                        # add current speed of the new entity\n",
    "                                    \n",
    "                                    # if no distances are abailable:\n",
    "                                    # -> create new entity\n",
    "                                    # -> for entity creation see above: \n",
    "                                    else:\n",
    "                                        entity = deque(maxlen = buffer)                \n",
    "                                        entity.appendleft(labels[label][1]+frame_counter_tuple)\n",
    "                                        entity_list.append(entity)                     \n",
    "\n",
    "                                        labels[label][0] = True\n",
    "                                        last_time_modified.append(0)\n",
    "                                        last_time_modified[entity_list.index(entity_list[-1])] = frame_counter  \n",
    "\n",
    "                                        is_active.append(False)                         \n",
    "                                        is_active[entity_list.index(entity_list[-1])] = True\n",
    "\n",
    "                                        is_entity_counted.append(False)\n",
    "\n",
    "                                        expected_next_center.append(labels[label][1][0]) \n",
    "                                        current_speed.append(0)\n",
    "                                        \n",
    "   \n",
    "                                    \n",
    "          ## Entity Assignment Case 1: ##\n",
    "          # no active entities -> Detection-Box of label list must belong to a new entity\n",
    "          # -> create a new entity for each   \n",
    "          else:                                                        \n",
    "              for label in range(len(labels)):               # for each D-Box in the label list:\n",
    "                  if labels[label][0] == False :             # check if the D-Box has been assigned yet\n",
    "                                                             # create a new entity\n",
    "                      entity = deque(maxlen=buffer)          # create entitiy and corresponding list entries\n",
    "                      entity.appendleft(labels[label][1]+frame_counter_tuple) \n",
    "                      entity_list.append(entity)             # append newly created entity to the entity list\n",
    "                                                              \n",
    "\n",
    "                      labels[label][0] = True                # D-Box has been assigned. assigned = True\n",
    "                      last_time_modified.append(0)           # append frame counter to the last_time_modified list\n",
    "                      last_time_modified[entity_list.index(entity_list[-1])] = frame_counter\n",
    "                      is_active.append(False)                # set up entity as an active entity, since it's new\n",
    "                      is_active[entity_list.index(entity_list[-1])] = True\n",
    "                      \n",
    "                      is_entity_counted.append(False)        # entity has not been counted yet, since it's new\n",
    "                        \n",
    "                      expected_next_center.append(labels[label][1][0]) # append entry for expected next center\n",
    "                      current_speed.append(0)                # append entry for current speed of the new entity\n",
    "                        \n",
    "                                      \n",
    " ########################################## END OF: ENTITY ASSIGNMENT    #################################################\n",
    " \n",
    " ################################# Start of: UPDATING ENTITIES AFTER ASIIGNMENT PROCESS    ###############################\n",
    "\n",
    " # these updating steps are used in order to prepare all entities for the assignment process for the next frame\n",
    " # during this update process, the following is done:\n",
    " # -> check if entites can be closed (deactivating entities)\n",
    " # -> based on this prepare a list of all active entities for the next frame\n",
    " # -> update hidden and visible status of entities\n",
    " # -> update movement speed of entities\n",
    " # -> update the current average speed based on the updated movement speeds of entities\n",
    " # -> based on movement speed: calculate expected next positions for entities for the next frame   \n",
    "\n",
    " # !!!! since the the code for a right and left movement direction is basically the same. only the righ version is described !!!!!\n",
    " # !!!! please scroll down to #### RIGHT MOVEMENT ####\n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    " #### LEFT MOVEMENT #####    \n",
    " #different behaviour for movement directions:\n",
    "      \n",
    "      if movement == \"left\":\n",
    "            #### is_active ####                                             \n",
    "          for active in active_entities:                                    # check if an entity is still active\n",
    "              if last_time_modified[active] + 3 < frame_counter:            # if : entity not updated for 3 frames?\n",
    "                  if entity_list[active][0][0]  < 0.05:                     # and last recorded position is in exit zone?\n",
    "                                                                            # -> proceed to deactivate the entity\n",
    "                        \n",
    "                                                                            # if the entity gets deactivated:\n",
    "                                                                            # calculate the distance to the next entity against the direction of movement\n",
    "                                                                            # this distance is later used for MISSING OBJECT IDENTIFIER\n",
    "                        \n",
    "                    # check distance for an entity once, when deactivating it\n",
    "                    # only take distance for entities which have successfully been counted\n",
    "                    if is_entity_counted[active]:\n",
    "                        \n",
    "                        # create list x_pos which will contain all center positions of currently counted hidden or visible entities\n",
    "                        x_pos = []\n",
    "                        for hidden in hidden_entities:\n",
    "                            if active != hidden:\n",
    "                                if is_entity_counted[hidden]:\n",
    "                                    x_pos.append(expected_next_center[hidden])\n",
    "                        for visible in visible_entities:\n",
    "                            if active != visible:\n",
    "                                if is_entity_counted[visible]:\n",
    "                                    x_pos.append(entity_list[visible][0][0])\n",
    "                        \n",
    "                        # if other active entities were found for a distance check:\n",
    "                        if len(x_pos) > 0:\n",
    "                            \n",
    "                            # sort the list of x_pos\n",
    "                            # the sorting setting of this list depends on the movement direction                            \n",
    "                            # for a right movement this has to be set on True (from right to left)\n",
    "                            x_pos.sort(reverse=False) \n",
    "                            # the sorting ensures that the next entity to the leaving one is chosen for the distance calculation\n",
    "                            \n",
    "                            # the distance is appended to the distance list for the later check\n",
    "                            # this will be needed for the missing vine checker later on\n",
    "                            # it works as follows:\n",
    "                            # if the next active entity to the currently leaving entity is hidden --> calculate abs distance to expected next center\n",
    "                            # if the next active entity to the currently leaving entity is visible --> calculate abs distance to this position\n",
    "                            if active in hidden_entities:\n",
    "                                entity_distance.append((active,abs(expected_next_center[active] - x_pos[0])))\n",
    "                            if active in visible_entities:  \n",
    "                                entity_distance.append((active,abs(entity_list[active][0][0] - x_pos[0])))\n",
    "                                \n",
    "                            \n",
    "                        # if ni other active entities were found for a distance check:\n",
    "                        # use a max range value for the distance\n",
    "                        # for right movement -> abs( position d-box - 10% of image with.)\n",
    "                        # for left movement -> abs( position d-box - 90% of image with. )\n",
    "                        else:\n",
    "                            entity_distance.append((active,abs(entity_list[active][0][0] - 0.1)))\n",
    "\n",
    "                            \n",
    "                    # Here the checkup screenshot is written in case the winemaker wants to verify a missing vine\n",
    "                    # the screenshot name contains the video_name + frame number + MSEC position in the video\n",
    "                    cv2.imwrite('vine_screenshots/'+video_name+\"_\"+str(frame_counter)+\"_\"+str(cap.get(cv2.CAP_PROP_POS_MSEC))+\"_vine.jpg\",image_np)    # Save Screenshot of frame if a vine leaves the screen\n",
    "                    \n",
    "                    # deactivate the entity afterwards\n",
    "                    is_active[active] = False                             \n",
    "                                        \n",
    "                    # append MSEC Position in a separate list with the entity number if it leaves the screen\n",
    "                    # this is important in order to match the missing vine with the specific gps location of the video later on\n",
    "                    # entity_MSEC = [(ID, MSEC), (ID, MSEC)]\n",
    "                    entity_MSEC.append((active,cap.get(cv2.CAP_PROP_POS_MSEC)))\n",
    "                    \n",
    "                  elif expected_next_center[active] < 0.05:                  # check if expected position is in exit zone?\n",
    "                                                                             # same procedure as above....\n",
    "                    if is_entity_counted[active]:\n",
    "                        \n",
    "                        x_pos = []\n",
    "                        for hidden in hidden_entities:\n",
    "                            if active != hidden:\n",
    "                                if is_entity_counted[hidden]:\n",
    "                                    x_pos.append(expected_next_center[hidden])\n",
    "                        for visible in visible_entities:\n",
    "                            if active != visible:\n",
    "                                if is_entity_counted[visible]:\n",
    "                                    x_pos.append(entity_list[visible][0][0])\n",
    "                        \n",
    "                        if len(x_pos) > 0:\n",
    "                            x_pos.sort(reverse=False) \n",
    "\n",
    "                            if active in hidden_entities:\n",
    "                                entity_distance.append((active,abs(expected_next_center[active] - x_pos[0])))\n",
    "                            if active in visible_entities:  \n",
    "                                entity_distance.append((active,abs(entity_list[active][0][0] - x_pos[0])))   \n",
    "                        else:\n",
    "                            entity_distance.append((active,abs(entity_list[active][0][0] - 0.1)))\n",
    "                                                \n",
    "                    cv2.imwrite('vine_screenshots/'+video_name+\"_\"+str(frame_counter)+\"_\"+str(cap.get(cv2.CAP_PROP_POS_MSEC))+\"_vine.jpg\",image_np)    # Save Screenshot of frame if a vine leaves the screen\n",
    "\n",
    "                    is_active[active] = False                           \n",
    "                    \n",
    "                    entity_MSEC.append((active,cap.get(cv2.CAP_PROP_POS_MSEC)))\n",
    "                    \n",
    "                  # if a Entity can not be updated again for a long time (90 frames or more)\n",
    "                  # -> deactivate the entity\n",
    "                  # -> if it was counted => reverse this count  \n",
    "                  elif last_time_modified[active] + 90 < frame_counter:  \n",
    "                    is_active[active] = False\n",
    "                    if is_entity_counted[active] == True:\n",
    "                        vine_counter = vine_counter-1\n",
    "                        \n",
    "              elif last_time_modified[active] + 60 < frame_counter: # eleminate entities going completly lost outside the exit box\n",
    "                    is_active[active] = False\n",
    "\n",
    "\n",
    "\n",
    "        ## active_entities ##\n",
    "        # this is used to update the list of active entities for the next frame\n",
    "        # get the indices for all active entities\n",
    "        # update the list of all currently active entities (active_entities)\n",
    "          active_entities.clear()\n",
    "          active_entities = [i for i, j in enumerate(is_active) if j == True]\n",
    "\n",
    "\n",
    "        ## visible entities and hidden entities ##\n",
    "        # this is used to update the list of hidden and visible entities for the next frame\n",
    "        # if a entity did not get an update since 3 frames -> assign it to the hidden entities list\n",
    "        # if a entity did get an update since 3 frames -> assign it to the visible entities list\n",
    "        #\n",
    "        # it is done by comparing the last time modified frame number with the current frame number\n",
    "          visible_entities = []\n",
    "          hidden_entities = []\n",
    "          for active in active_entities:\n",
    "                if last_time_modified[active]+3 > frame_counter:\n",
    "                    visible_entities.append(active)\n",
    "                else:\n",
    "                    hidden_entities.append(active)\n",
    "\n",
    "        ## current_speed ##\n",
    "        # calculate the moving speed for each active entitiy\n",
    "        # a speed can only be calculated if the entity has at least 2 entries of known positions on frames\n",
    "        # \n",
    "          for active in active_entities:\n",
    "        # check if the entity has 2 entries:\n",
    "        # if yes: calculate the speed\n",
    "              if len(entity_list[active]) >= 2 :\n",
    "                  diff = []\n",
    "                    \n",
    "                  for k in range(len(entity_list[active])-1):\n",
    "                      diff.append(0)\n",
    "                      # calculate the difference of consecutive X-Positions of the center of an entity\n",
    "                      # if this difference for a center pair is negative for a right movement -> use the avg_speed instead\n",
    "                      # this ensures that the speed is always aligned to the movement direction\n",
    "                      # since vines are static it should not be possible that they have a negative movement speed\n",
    "                      # therefore this condition is used\n",
    "                      if (entity_list[active][k][0] - entity_list[active][k+1][0]) >= 0 :                \n",
    "                          # the difference is normalized since there might frame gaps between center pairs\n",
    "                          # therefore the difference is divided by the difference between the framenumbers of the center pairs\n",
    "                          #  normalized difference = x_value_center[k] - x_value_center[k+1] / framenumber[k] - framenumber[k+1]\n",
    "                          diff[k] = (entity_list[active][k][0] - entity_list[active][k+1][0])/(entity_list[active][k][2]-entity_list[active][k+1][2])\n",
    "                      else:\n",
    "                          diff[k] = avg_speed\n",
    "                  # the current speed is the average of all distances between the consecutive X-Positions of the center of an entity         \n",
    "                  current_speed[active] = sum(diff) / (len(entity_list[active])-1)\n",
    "                    \n",
    "                  # dampening the speed if it makes too high of a spike\n",
    "                  # this can be used to dampen the speed if needed\n",
    "                    \n",
    "                  #if current_speed[active]*2.5 >= avg_speed:\n",
    "                  #      current_speed[active] = current_speed[active]*0.8\n",
    "                  #      #current_speed[active] = avg_speed\n",
    "                  #else:\n",
    "                  #      current_speed[active] = current_speed[active]\n",
    "                        \n",
    "\n",
    "          # if no: use the avg_speed over all entities instead until it has at least 2 entries\n",
    "          # see avg_speed below\n",
    "              else:\n",
    "                  current_speed[active] = avg_speed #durch avg ersetzen\n",
    "        \n",
    "        ## expected_next_center ##                             \n",
    "        # calculate the expected position for each active entities for the next frame\n",
    "        # check if the entity got an update on the current frame\n",
    "        # if it got updated: use the current center position of the assigned detection box and move it by the speed of the entity\n",
    "          for active in active_entities:    \n",
    "               if last_time_modified[active] == frame_counter: \n",
    "                   expected_next_center[active] = entity_list[active][0][0] + current_speed[active]\n",
    "        # if it did not get an update: use the last expected position of the entity and move it by the speed of the entity\n",
    "               elif last_time_modified[active] < frame_counter: \n",
    "                    expected_next_center[active] = expected_next_center[active] + current_speed[active]\n",
    "      \n",
    "    \n",
    "    ## average entity speed ##\n",
    "    # calculate the average entity speed\n",
    "    # use the values of the movement speed of all currently acitve entities\n",
    "    # calculate the average over them\n",
    "    \n",
    "    # this is needed for the calculation of the expected next position of a hidden entitie:\n",
    "    # if it was only seen once after it turned into the hidden status there is no possibility to calculate the speed of it\n",
    "    # therefore the avg_speed is needed \n",
    "      speeds = []\n",
    "      for active in active_entities:\n",
    "            #get the current speed\n",
    "            speeds.append(current_speed[active])\n",
    "      if len(active_entities) > 0:\n",
    "          avg_speed = (sum(speeds)/(len(speeds)))  \n",
    "        \n",
    "      \n",
    " #### RIGHT MOVEMENT #####        \n",
    "      if movement == \"right\":\n",
    "            #### is_active ####                                             \n",
    "          for active in active_entities:                                    # check if an entity is still active\n",
    "              if last_time_modified[active] + 3 < frame_counter:            # if : entity not updated for 3 frames?\n",
    "                  if entity_list[active][0][0]  > 0.95:                     # and last recorded position is in exit zone?\n",
    "                                                                            # -> proceed to deactivate the entity\n",
    "                        \n",
    "                                                                            # if the entity gets deactivated:\n",
    "                                                                            # calculate the distance to the next entity against the direction of movement\n",
    "                                                                            # this distance is later used for MISSING OBJECT IDENTIFIER\n",
    "                        \n",
    "                    # check distance for an entity once, when deactivating it\n",
    "                    # only take distance for entities which have successfully been counted\n",
    "                    if is_entity_counted[active]:\n",
    "                        \n",
    "                        # create list x_pos which will contain all center positions of currently counted hidden or visible entities\n",
    "                        x_pos = []\n",
    "                        for hidden in hidden_entities:\n",
    "                            if active != hidden:\n",
    "                                if is_entity_counted[hidden]:\n",
    "                                    x_pos.append(expected_next_center[hidden])\n",
    "                        for visible in visible_entities:\n",
    "                            if active != visible:\n",
    "                                if is_entity_counted[visible]:\n",
    "                                    x_pos.append(entity_list[visible][0][0])\n",
    "                        \n",
    "                        # if other active entities were found for a distance check:\n",
    "                        if len(x_pos) > 0:\n",
    "                            \n",
    "                            # sort the list of x_pos\n",
    "                            # the sorting setting of this list depends on the movement direction                            \n",
    "                            # for a right movement this has to be set on True (from right to left)\n",
    "                            x_pos.sort(reverse=True) \n",
    "                            # the sorting ensures that the next entity to the leaving one is chosen for the distance calculation\n",
    "                            \n",
    "                            # the distance is appended to the distance list for the later check\n",
    "                            # this will be needed for the missing vine checker later on\n",
    "                            # it works as follows:\n",
    "                            # if the next active entity to the currently leaving entity is hidden --> calculate abs distance to expected next center\n",
    "                            # if the next active entity to the currently leaving entity is visible --> calculate abs distance to this position\n",
    "                            if active in hidden_entities:\n",
    "                                entity_distance.append((active,abs(expected_next_center[active] - x_pos[0])))\n",
    "                            if active in visible_entities:  \n",
    "                                entity_distance.append((active,abs(entity_list[active][0][0] - x_pos[0])))\n",
    "                                \n",
    "                            \n",
    "                        # if ni other active entities were found for a distance check:\n",
    "                        # use a max range value for the distance\n",
    "                        # for right movement -> abs( position d-box - 10% of image with.)\n",
    "                        # for left movement -> abs( position d-box - 90% of image with. )\n",
    "                        else:\n",
    "                            entity_distance.append((active,abs(entity_list[active][0][0] - 0.1)))\n",
    "\n",
    "                            \n",
    "                    # Here the checkup screenshot is written in case the winemaker wants to verify a missing vine\n",
    "                    # the screenshot name contains the video_name + frame number + MSEC position in the video\n",
    "                    cv2.imwrite('vine_screenshots/'+video_name+\"_\"+str(frame_counter)+\"_\"+str(cap.get(cv2.CAP_PROP_POS_MSEC))+\"_vine.jpg\",image_np)    # Save Screenshot of frame if a vine leaves the screen\n",
    "                    \n",
    "                    # deactivate the entity afterwards\n",
    "                    is_active[active] = False                             \n",
    "                                        \n",
    "                    # append MSEC Position in a separate list with the entity number if it leaves the screen\n",
    "                    # this is important in order to match the missing vine with the specific gps location of the video later on\n",
    "                    # entity_MSEC = [(ID, MSEC), (ID, MSEC)]\n",
    "                    entity_MSEC.append((active,cap.get(cv2.CAP_PROP_POS_MSEC)))\n",
    "                    \n",
    "                  elif expected_next_center[active] > 0.95:                  # check if expected position is in exit zone?\n",
    "                                                                             # same procedure as above....\n",
    "                    if is_entity_counted[active]:\n",
    "                        \n",
    "                        x_pos = []\n",
    "                        for hidden in hidden_entities:\n",
    "                            if active != hidden:\n",
    "                                if is_entity_counted[hidden]:\n",
    "                                    x_pos.append(expected_next_center[hidden])\n",
    "                        for visible in visible_entities:\n",
    "                            if active != visible:\n",
    "                                if is_entity_counted[visible]:\n",
    "                                    x_pos.append(entity_list[visible][0][0])\n",
    "                        \n",
    "                        if len(x_pos) > 0:\n",
    "                            x_pos.sort(reverse=True) \n",
    "\n",
    "                            if active in hidden_entities:\n",
    "                                entity_distance.append((active,abs(expected_next_center[active] - x_pos[0])))\n",
    "                            if active in visible_entities:  \n",
    "                                entity_distance.append((active,abs(entity_list[active][0][0] - x_pos[0])))   \n",
    "                        else:\n",
    "                            entity_distance.append((active,abs(entity_list[active][0][0] - 0.1)))\n",
    "                                                \n",
    "                    cv2.imwrite('vine_screenshots/'+video_name+\"_\"+str(frame_counter)+\"_\"+str(cap.get(cv2.CAP_PROP_POS_MSEC))+\"_vine.jpg\",image_np)    # Save Screenshot of frame if a vine leaves the screen\n",
    "\n",
    "                    is_active[active] = False                           \n",
    "                    \n",
    "                    entity_MSEC.append((active,cap.get(cv2.CAP_PROP_POS_MSEC)))\n",
    "                    \n",
    "                  # if a Entity can not be updated again for a long time (90 frames or more)\n",
    "                  # -> deactivate the entity\n",
    "                  # -> if it was counted => reverse this count  \n",
    "                  elif last_time_modified[active] + 90 < frame_counter:  \n",
    "                    is_active[active] = False\n",
    "                    if is_entity_counted[active] == True:\n",
    "                        vine_counter = vine_counter-1\n",
    "                        \n",
    "              elif last_time_modified[active] + 60 < frame_counter: # eleminate entities going completly lost outside the exit box\n",
    "                    is_active[active] = False\n",
    "\n",
    "\n",
    "\n",
    "        ## active_entities ##\n",
    "        # this is used to update the list of active entities for the next frame\n",
    "        # get the indices for all active entities\n",
    "        # update the list of all currently active entities (active_entities)\n",
    "          active_entities.clear()\n",
    "          active_entities = [i for i, j in enumerate(is_active) if j == True]\n",
    "\n",
    "\n",
    "        ## visible entities and hidden entities ##\n",
    "        # this is used to update the list of hidden and visible entities for the next frame\n",
    "        # if a entity did not get an update since 3 frames -> assign it to the hidden entities list\n",
    "        # if a entity did get an update since 3 frames -> assign it to the visible entities list\n",
    "        #\n",
    "        # it is done by comparing the last time modified frame number with the current frame number\n",
    "          visible_entities = []\n",
    "          hidden_entities = []\n",
    "          for active in active_entities:\n",
    "                if last_time_modified[active]+3 > frame_counter:\n",
    "                    visible_entities.append(active)\n",
    "                else:\n",
    "                    hidden_entities.append(active)\n",
    "\n",
    "        ## current_speed ##\n",
    "        # calculate the moving speed for each active entitiy\n",
    "        # a speed can only be calculated if the entity has at least 2 entries of known positions on frames\n",
    "        # \n",
    "          for active in active_entities:\n",
    "        # check if the entity has 2 entries:\n",
    "        # if yes: calculate the speed\n",
    "              if len(entity_list[active]) >= 2 :\n",
    "                  diff = []\n",
    "                    \n",
    "                  for k in range(len(entity_list[active])-1):\n",
    "                      diff.append(0)\n",
    "                      # calculate the difference of consecutive X-Positions of the center of an entity\n",
    "                      # if this difference for a center pair is negative for a right movement -> use the avg_speed instead\n",
    "                      # this ensures that the speed is always aligned to the movement direction\n",
    "                      # since vines are static it should not be possible that they have a negative movement speed\n",
    "                      # therefore this condition is used\n",
    "                      if (entity_list[active][k][0] - entity_list[active][k+1][0]) >= 0 :                \n",
    "                          # the difference is normalized since there might frame gaps between center pairs\n",
    "                          # therefore the difference is divided by the difference between the framenumbers of the center pairs\n",
    "                          #  normalized difference = x_value_center[k] - x_value_center[k+1] / framenumber[k] - framenumber[k+1]\n",
    "                          diff[k] = (entity_list[active][k][0] - entity_list[active][k+1][0])/(entity_list[active][k][2]-entity_list[active][k+1][2])\n",
    "                      else:\n",
    "                          diff[k] = avg_speed\n",
    "                  # the current speed is the average of all distances between the consecutive X-Positions of the center of an entity         \n",
    "                  current_speed[active] = sum(diff) / (len(entity_list[active])-1)\n",
    "                    \n",
    "                  # dampening the speed if it makes too high of a spike\n",
    "                  # this can be used to dampen the speed if needed\n",
    "                    \n",
    "                  #if current_speed[active]*2.5 >= avg_speed:\n",
    "                  #      current_speed[active] = current_speed[active]*0.8\n",
    "                  #      #current_speed[active] = avg_speed\n",
    "                  #else:\n",
    "                  #      current_speed[active] = current_speed[active]\n",
    "                        \n",
    "\n",
    "          # if no: use the avg_speed over all entities instead until it has at least 2 entries\n",
    "          # see avg_speed below\n",
    "              else:\n",
    "                  current_speed[active] = avg_speed #durch avg ersetzen\n",
    "        \n",
    "        ## expected_next_center ##                             \n",
    "        # calculate the expected position for each active entities for the next frame\n",
    "        # check if the entity got an update on the current frame\n",
    "        # if it got updated: use the current center position of the assigned detection box and move it by the speed of the entity\n",
    "          for active in active_entities:    \n",
    "               if last_time_modified[active] == frame_counter: \n",
    "                   expected_next_center[active] = entity_list[active][0][0] + current_speed[active]\n",
    "        # if it did not get an update: use the last expected position of the entity and move it by the speed of the entity\n",
    "               elif last_time_modified[active] < frame_counter: \n",
    "                    expected_next_center[active] = expected_next_center[active] + current_speed[active]\n",
    "      \n",
    "    \n",
    "    ## average entity speed ##\n",
    "    # calculate the average entity speed\n",
    "    # use the values of the movement speed of all currently acitve entities\n",
    "    # calculate the average over them\n",
    "    \n",
    "    # this is needed for the calculation of the expected next position of a hidden entitie:\n",
    "    # if it was only seen once after it turned into the hidden status there is no possibility to calculate the speed of it\n",
    "    # therefore the avg_speed is needed \n",
    "      speeds = []\n",
    "      for active in active_entities:\n",
    "            #get the current speed\n",
    "            speeds.append(current_speed[active])\n",
    "      if len(active_entities) > 0:\n",
    "          avg_speed = (sum(speeds)/(len(speeds)))\n",
    "  \n",
    "    \n",
    "    ## movement update ##\n",
    "      # can be used to adapt to a changing movement direction within a video\n",
    "      # not needed for this given prototype\n",
    "    \n",
    "      #if avg_speed < 0:\n",
    "      #    movement = \"left\"\n",
    "      #elif avg_speed > 0:\n",
    "      #    movement = \"right\"\n",
    "      #else:\n",
    "      #    movement = movement\n",
    "    \n",
    "  ################################# END OF: UPDATING ENTITIES AFTER ASIIGNMENT PROCESS   ##################################\n",
    "    \n",
    "  #<---------------------------------------------- END OF: OBJECT TRACKING   --------------------------------------------> \n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "  #<---------------------------------------------- START OF: OBJECT COUNTER   -------------------------------------------->\n",
    "\n",
    "    \n",
    "    \n",
    "      ## vine counter ##\n",
    "      # increase vine_counter (only if 10+ labels belong to one entity)\n",
    "      # a vine is only counted if the entity got appended a certain amount of matching objects\n",
    "      # only counted if above a certain count_threshold. this threshold was setup in the beginning (currently 10)\n",
    "      for active in active_entities:\n",
    "        if is_entity_counted[active] == False and len(entity_list[active]) > count_threshold :\n",
    "            is_entity_counted[active] = True\n",
    "            vine_counter += 1\n",
    "                              \n",
    "  #<---------------------------------------------- END OF: OBJECT COUNTER   ---------------------------------------------->\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "  #<----------------------------------------------- START OF: VISUALIZATION   -------------------------------------------->\n",
    "    \n",
    "    # This section is used in order to visualize the actual object detection, object tracking and counting.\n",
    "    # It is not needed for the functionallity of the system and is only used to visualize the algorithm. \n",
    "    # -> Visualization of object detection, object tracking and object counting\n",
    "    #\n",
    "    # A window will pop up which will show the application for the chosen video.\n",
    "    # In order to exit the application press 'q' while it's running.\n",
    "    \n",
    "      # get visualizations for the detection-boxes\n",
    "      vis_util.visualize_boxes_and_labels_on_image_array(\n",
    "        image_np,\n",
    "        np.squeeze(boxes),\n",
    "        np.squeeze(classes).astype(np.int32),\n",
    "        np.squeeze(scores),\n",
    "        category_index,\n",
    "        use_normalized_coordinates=True,\n",
    "        line_thickness=8)\n",
    "      \n",
    "      # get visualizations for the active entities\n",
    "      # it is only needed to visualize active ones since they are the only one that are currently on the screen\n",
    "      for active in active_entities:\n",
    "                                              \n",
    "          for i in range(1, len(entity_list[active])):\n",
    "                  # check if the entity has at least two entries in the deque list (two known positions)\n",
    "                  # if not, no line can be drawn\n",
    "                  if entity_list[active][i - 1] is None or entity_list[active][i] is None:\n",
    "                      continue\n",
    "                  \n",
    "                  # draw a line the line of the last known positions of the entity\n",
    "                  # this draws an line between the last known positions\n",
    "                  # *w and *h is used to convert the relative positions into actual pixel positions which can be drawn\n",
    "                  thickness = 5  \n",
    "                  x1 = round(entity_list[active][i - 1][0] * w)\n",
    "                  y1 = round(entity_list[active][i - 1][1] * h)\n",
    "                  x2 = round(entity_list[active][i][0] * w)\n",
    "                  y2 = round(entity_list[active][i][1] * h)\n",
    "                  cv2.line(image_np, (x1,y1), (x2,y2), (255,255,0), thickness)\n",
    "                  \n",
    "          # draw a dot for the expected next center\n",
    "          x3 = round(expected_next_center[active] * w)\n",
    "          y3 = round(entity_list[active][0][1] * h)\n",
    "          cv2.circle(image_np, (x3,y3) , 13, (255 , 0, 0), thickness=-1, lineType=8, shift = 0)\n",
    "          # cv2.circle(img, center, radius, color, thickness=1, lineType=8, shift=0)\n",
    "          \n",
    "          # draw the id of the entity into the corresponding expected center of it\n",
    "          # the -9 and +9 is used the align it somewhere in the actual center of the dot\n",
    "          font = cv2.FONT_HERSHEY_SIMPLEX\n",
    "          cv2.putText(image_np,str(active),(x3-9,y3+9), font, 0.6,(255,255,255),2,cv2.LINE_AA)\n",
    "                  \n",
    "          # draw the current vine counter in the upper left corner (50,50) of the image\n",
    "          font = cv2.FONT_HERSHEY_SIMPLEX\n",
    "          cv2.putText(image_np,('counted vines: ' + str(vine_counter)),(50,50), font, 1,(255, 0, 0),2,cv2.LINE_AA)  \n",
    "\n",
    "      # show the window with the vizualizations\n",
    "      # setup breakup of the  via pressing 'q'\n",
    "      cv2.imshow('object detection window',image_np) \n",
    "      \n",
    "      #cv2.resize(image_np, (1600,900))  -> this can be used if the window scale is too big for the screen\n",
    "      if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "               break\n",
    "    \n",
    "   #<----------------------------------------------- END OF: VISUALIZATION   -------------------------------------------->\n",
    "    \n",
    "    \n",
    "    # release the video after it has been processed\n",
    "    cap.release()\n",
    "    cv2.destroyAllWindows() "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Result of the Object Counter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(vine_counter)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## MISSING OBJECT IDENTIFIER\n",
    "* calculate mean distance between vines for the video\n",
    "* based on this mean distance -> identify positions of missing vines"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##  get distances of detected objects (vines)\n",
    "##  append these distance to the list vines_distances\n",
    "vines_distances = []\n",
    "for i in range(len(entity_distance)):\n",
    "    vines_distances.append(entity_distance[i][1])\n",
    "\n",
    "# calculate the std and mean distance for the video    \n",
    "std_dist = np.std(vines_distances)\n",
    "mean_dist = sum(vines_distances)/len(vines_distances)\n",
    "\n",
    "# delete outlier distances in order to calculate a more accurate mean distance\n",
    "# -> delete outliers and calculate clean_mean and clean_std for the distances of the given video\n",
    "cleaned_vines_distances = []\n",
    "for i in range(len(vines_distances)):\n",
    "    # A threshold of 1.5 times the actual mean distance is used to detect outliers\n",
    "    if (abs(float(vines_distances[i])-float(mean_dist))) < 1.5 * float(std_dist):\n",
    "        cleaned_vines_distances.append(vines_distances[i])\n",
    "\n",
    "# calculate and pringt out the cleaned versions of std and mean for the distances       \n",
    "std_dist_cleaned = np.std(cleaned_vines_distances)\n",
    "print(\"std_dist_cleaned\"+str(std_dist_cleaned))        \n",
    "mean_dist_cleaned = sum(cleaned_vines_distances)/len(cleaned_vines_distances)\n",
    "print(\"mean_dist_cleaned\"+str(mean_dist_cleaned))\n",
    "\n",
    "# set up list for missing vines\n",
    "missing_vines_msec_locations = []\n",
    "\n",
    "for k in range(len(vines_distances)):\n",
    "    \n",
    "    # create list of missing vines locations\n",
    "    # if a distance to the next vine is larger than 1.8 times the mean distance -> a missing object (vine) is detected\n",
    "    if vines_distances[k] > 1.8 * mean_dist_cleaned:    # can easily be adjusted\n",
    "        for m in range(len(entity_MSEC)):\n",
    "            if entity_MSEC[m][0] == entity_distance[k][0]:       \n",
    "                if movement==\"right\":\n",
    "                    print(\"Missing Vine on the left of entity \" + str(entity_distance[k][0]) + \"at MSEC: \"+ str(entity_MSEC[m][1]) + \" in the Video \" )\n",
    "                    missing_vines_msec_locations.append(entity_MSEC[m])\n",
    "                else:\n",
    "                    print(\"Missing Vine on the right of entity  \" + str(entity_distance[k][0]) + \"at MSEC: \"+ str(entity_MSEC[m][1]) + \" in the Video \"  )\n",
    "                    \n",
    "# show all missing vines with their msec positions in the video\n",
    "print(missing_vines_msec_locations)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Result of the Missing Object Identifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(len(missing_vines_msec_locations))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Output Processing\n",
    "* combine vine counter and missing vine positions with the gps-data of the video\n",
    "* visualize the result on an interactive map"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import datetime\n",
    "import os\n",
    "import cv2\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from research.object_detection.utils import visualization_utils as vis_util\n",
    "from PIL import Image\n",
    "import folium\n",
    "from matplotlib import pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "video_name"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Read the gps-information of  the csv file\n",
    "* only extract the timestamp, latitude and longitude\n",
    "* rename these fields to date, lat and lon\n",
    "* adjust the format of the timestamp field (this is set up for the sepicific used csv files)\n",
    "* for csv files in another format, this section has to be changed\n",
    "* -> it is set up to work for the csv files of the used sample videos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import datetime\n",
    "\n",
    "dataframe_gps = pd.read_csv(video_name+'_Hero7 Black-GPS5.csv', sep=',')\n",
    "dataframe_gps = dataframe_gps[['date','GPS (Lat.) [deg]','GPS (Long.) [deg]' ]]\n",
    "dataframe_gps = dataframe_gps.rename(columns={\"GPS (Lat.) [deg]\": \"lat\", \"GPS (Long.) [deg]\": \"lon\"})\n",
    "dataframe_gps['date'] = dataframe_gps['date'].str[-13:].str[:12]\n",
    "dataframe_gps[('date')] = pd.to_datetime(dataframe_gps[('date')])\n",
    "\n",
    "dataframe_gps.head(10)\n",
    "#dataframe_gps.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Convert date formats and Calculate relative timestamp in the video\n",
    "* convert the date format to datetime\n",
    "* calculate the relative timestampf (diff) for each GPS-timestamp in the video\n",
    "* in order to do this: take each timestamp and subtract the min timestamp for each"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataframe_gps[('date')] = pd.to_datetime(dataframe_gps[('date')])\n",
    "dataframe_gps[('date')] = pd.to_datetime(dataframe_gps[('date')])\n",
    "max(dataframe_gps[('date')])\n",
    "#dataframe_gps.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "datediff = dataframe_gps[('date')] - min(dataframe_gps[('date')])\n",
    "dataframe_gps[('diff')] = datediff\n",
    "dataframe_gps.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Calculate the millisecond for each relative timestamp in the video\n",
    "* calculate the millisecond position (MSEC) in the video for each GPS-information\n",
    "* this MSEC is needed in order to assign identified missing objects (missing vines) to actual gps-positions of the video"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "MSEC_all = []    \n",
    "for index, row in dataframe_gps.iterrows():\n",
    "\n",
    "    row[('diff')] = row[('diff')].total_seconds()*1000\n",
    "    MSEC_all.append(row[('diff')])\n",
    "\n",
    "\n",
    "MSEC_all = np.array(MSEC_all)\n",
    "\n",
    "dataframe_gps[('MSEC')] = MSEC_all\n",
    "dataframe_gps.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create final dataframe for the map creation\n",
    "* consisting of: MSEC, lat, lon"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataframe_gps = dataframe_gps[['MSEC', 'lat', 'lon']]\n",
    "dataframe_gps.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create dataframe for all identified missing objects (missing vines)\n",
    "* create a dataframe also consisting of: MSEC, lat, lon\n",
    "* compare the millisecond positions of the missing vines with the millisecond positions of available gps-timestamps of the video\n",
    "* assign a missing vine to the gps-position of the video with the smallest difference between both millisecond positions\n",
    "* min ( abs (MSEC of missing vine - MSEC of a gps-position of the video))\n",
    "* add matched missing vine gps-locations to the dataframe missing_v"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "missing_vines_msec_locations\n",
    "fehlstellen_counter = len(missing_vines_msec_locations)\n",
    "fehlstellen_counter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "missing_v = pd.DataFrame(columns=['MSEC','lat','lon'])\n",
    "\n",
    "for k in range(len(missing_vines_msec_locations)):\n",
    "    #print(missing_vines_msec_locations[k][1])\n",
    "    \n",
    "    loc = dataframe_gps.loc[(dataframe_gps['MSEC']-missing_vines_msec_locations[k][1]).abs().argsort()[:1]]\n",
    "    loc = loc.values\n",
    "    \n",
    "    missing_v = missing_v.append(pd.Series([loc[0][0], loc[0][1], loc[0][2]], index=missing_v.columns ), ignore_index=True)\n",
    "\n",
    "missing_v"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Set up map creation\n",
    "* create the base map with folium\n",
    "* add the line for the vineyard to the map\n",
    "* add the points for missing vines to the map "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# make sure the gps-data of the video is saved as float format\n",
    "dataframe_gps['lat'] = dataframe_gps['lat'].astype(float)\n",
    "dataframe_gps['lon'] = dataframe_gps['lon'].astype(float)\n",
    "\n",
    "\n",
    "# calculate max value for dynamic map scaling\n",
    "# this is used in order to get an adjusted initial view for the created map\n",
    "min_lat = float(dataframe_gps['lat'].min())\n",
    "min_lon = float(dataframe_gps['lon'].min())\n",
    "\n",
    "# make sure the gps-data of missing vines is saved as float format\n",
    "missing_v['lat'] = missing_v['lat'].astype(float)\n",
    "missing_v['lon'] = missing_v['lon'].astype(float)\n",
    "\n",
    "# create the acutal map visual with folium\n",
    "# use the calculated min and max values for lat and lon as an entry point for the map\n",
    "map_visual = folium.Map(location=[min_lat, min_lon], zoom_start=35, )\n",
    "\n",
    "\n",
    "# add the vineyard to the map\n",
    "# draws every available gps-position of the video as a blue point on the map\n",
    "# -> resulting in a line which represents a vineyard\n",
    "# -> for each point on this line add a popup functionallity is added which shows the following by clicking on it:\n",
    "# -> \"There are X vines an Y missing vines in this row / Z% missing vines for this row\"\n",
    "for index, row in dataframe_gps.iterrows():\n",
    "        folium.CircleMarker([row['lat'], row['lon']],\n",
    "                            radius=0.2,\n",
    "                            popup=\"There are \"+\" \"+str(vine_counter)+\" vines and \" +  str(fehlstellen_counter)+\" missing vine(s) in this row /  \"+ str(round(fehlstellen_counter/vine_counter, 2)*100)+\"% missing vines for this row\",\n",
    "                            fill_color=\"#f53220\",\n",
    "                           ).add_to(map_visual)\n",
    "\n",
    "\n",
    "\n",
    "# add the positions of the missing vines to the map\n",
    "# draws every gps-position of a missing vine as red circle to a point on the map\n",
    "# -> for each point a popup functionallity is added which shows the following by clicking on it:\n",
    "# -> \"missing vine number X at Latitude: (lat) and Longitude (lon)\n",
    "count = 0\n",
    "for index, row in missing_v.iterrows():\n",
    "    print(row['lat'])\n",
    "    print(row['lon'])\n",
    "    count = count + 1\n",
    "    folium.Circle([row['lat'], row['lon']],\n",
    "                            radius=1.2,\n",
    "                            popup=\"missing vine (\"+ str(count)+\") at Latitude: \"+ str(row['lat'])+\" and Longitude: \"+str(row['lon']),\n",
    "                            color=\"crimson\",\n",
    "                           ).add_to(map_visual)\n",
    "    \n",
    "print(\"map ready to be created\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create the finished map\n",
    "* same the resulting output map\n",
    "* saves the map in the \"gps_output\" directory which must exist in the directory this skript is executed\n",
    "* the output name of the map will depend on the name of the used video\n",
    "* e.g. \"video_9_GPS_output.html\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "map_visual.save(os.path.join('gps_output', video_name+'_GPS_output.html'))"
   ]
  }
 ],
 "metadata": {
  "celltoolbar": "Raw Cell Format",
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
